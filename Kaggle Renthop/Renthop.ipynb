{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning processing....\n",
      "Checkpoint-1\n",
      "49352\n",
      "74659\n",
      "Checkpoint-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santanu/tensorflowGPU/lib/python2.7/site-packages/ipykernel/__main__.py:230: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/santanu/tensorflowGPU/lib/python2.7/site-packages/ipykernel/__main__.py:231: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santanu/tensorflowGPU/lib/python2.7/site-packages/ipykernel/__main__.py:267: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/santanu/tensorflowGPU/lib/python2.7/site-packages/ipykernel/__main__.py:268: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/santanu/tensorflowGPU/lib/python2.7/site-packages/ipykernel/__main__.py:269: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/santanu/tensorflowGPU/lib/python2.7/site-packages/ipykernel/__main__.py:296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/santanu/tensorflowGPU/lib/python2.7/site-packages/ipykernel/__main__.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/santanu/tensorflowGPU/lib/python2.7/site-packages/ipykernel/__main__.py:298: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/santanu/tensorflowGPU/lib/python2.7/site-packages/ipykernel/__main__.py:309: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/santanu/tensorflowGPU/lib/python2.7/site-packages/ipykernel/__main__.py:310: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/santanu/tensorflowGPU/lib/python2.7/site-packages/ipykernel/__main__.py:313: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/santanu/tensorflowGPU/lib/python2.7/site-packages/ipykernel/__main__.py:314: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint-4\n",
      "[0]\ttrain-mlogloss:1.08484\ttest-mlogloss:1.08497\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[10]\ttrain-mlogloss:0.968686\ttest-mlogloss:0.970552\n",
      "[20]\ttrain-mlogloss:0.881821\ttest-mlogloss:0.885694\n",
      "[30]\ttrain-mlogloss:0.814872\ttest-mlogloss:0.820595\n",
      "[40]\ttrain-mlogloss:0.763279\ttest-mlogloss:0.770703\n",
      "[50]\ttrain-mlogloss:0.722458\ttest-mlogloss:0.731413\n",
      "[60]\ttrain-mlogloss:0.689608\ttest-mlogloss:0.700242\n",
      "[70]\ttrain-mlogloss:0.6632\ttest-mlogloss:0.675482\n",
      "[80]\ttrain-mlogloss:0.641167\ttest-mlogloss:0.655138\n",
      "[90]\ttrain-mlogloss:0.623203\ttest-mlogloss:0.638821\n",
      "[100]\ttrain-mlogloss:0.608049\ttest-mlogloss:0.625306\n",
      "[110]\ttrain-mlogloss:0.595006\ttest-mlogloss:0.613638\n",
      "[120]\ttrain-mlogloss:0.583837\ttest-mlogloss:0.603891\n",
      "[130]\ttrain-mlogloss:0.574177\ttest-mlogloss:0.595553\n",
      "[140]\ttrain-mlogloss:0.565577\ttest-mlogloss:0.588348\n",
      "[150]\ttrain-mlogloss:0.55826\ttest-mlogloss:0.582544\n",
      "[160]\ttrain-mlogloss:0.551796\ttest-mlogloss:0.57746\n",
      "[170]\ttrain-mlogloss:0.545842\ttest-mlogloss:0.572899\n",
      "[180]\ttrain-mlogloss:0.540439\ttest-mlogloss:0.568908\n",
      "[190]\ttrain-mlogloss:0.535446\ttest-mlogloss:0.565328\n",
      "[200]\ttrain-mlogloss:0.530811\ttest-mlogloss:0.56219\n",
      "[210]\ttrain-mlogloss:0.526807\ttest-mlogloss:0.559486\n",
      "[220]\ttrain-mlogloss:0.522861\ttest-mlogloss:0.556897\n",
      "[230]\ttrain-mlogloss:0.519045\ttest-mlogloss:0.554326\n",
      "[240]\ttrain-mlogloss:0.515478\ttest-mlogloss:0.552225\n",
      "[250]\ttrain-mlogloss:0.512196\ttest-mlogloss:0.550197\n",
      "[260]\ttrain-mlogloss:0.509182\ttest-mlogloss:0.548443\n",
      "[270]\ttrain-mlogloss:0.506321\ttest-mlogloss:0.546905\n",
      "[280]\ttrain-mlogloss:0.503514\ttest-mlogloss:0.545389\n",
      "[290]\ttrain-mlogloss:0.500822\ttest-mlogloss:0.543948\n",
      "[300]\ttrain-mlogloss:0.498054\ttest-mlogloss:0.542525\n",
      "[310]\ttrain-mlogloss:0.495705\ttest-mlogloss:0.541253\n",
      "[320]\ttrain-mlogloss:0.493288\ttest-mlogloss:0.540084\n",
      "[330]\ttrain-mlogloss:0.490901\ttest-mlogloss:0.538945\n",
      "[340]\ttrain-mlogloss:0.488519\ttest-mlogloss:0.537769\n",
      "[350]\ttrain-mlogloss:0.486646\ttest-mlogloss:0.536909\n",
      "[360]\ttrain-mlogloss:0.48467\ttest-mlogloss:0.535958\n",
      "[370]\ttrain-mlogloss:0.482644\ttest-mlogloss:0.535141\n",
      "[380]\ttrain-mlogloss:0.480502\ttest-mlogloss:0.534215\n",
      "[390]\ttrain-mlogloss:0.478588\ttest-mlogloss:0.533455\n",
      "[400]\ttrain-mlogloss:0.477118\ttest-mlogloss:0.532772\n",
      "[410]\ttrain-mlogloss:0.475433\ttest-mlogloss:0.532066\n",
      "[420]\ttrain-mlogloss:0.47392\ttest-mlogloss:0.531344\n",
      "[430]\ttrain-mlogloss:0.472151\ttest-mlogloss:0.530752\n",
      "[440]\ttrain-mlogloss:0.470419\ttest-mlogloss:0.530035\n",
      "[450]\ttrain-mlogloss:0.468908\ttest-mlogloss:0.52945\n",
      "[460]\ttrain-mlogloss:0.467322\ttest-mlogloss:0.528894\n",
      "[470]\ttrain-mlogloss:0.465911\ttest-mlogloss:0.528333\n",
      "[480]\ttrain-mlogloss:0.464553\ttest-mlogloss:0.527795\n",
      "[490]\ttrain-mlogloss:0.463034\ttest-mlogloss:0.527309\n",
      "[500]\ttrain-mlogloss:0.461639\ttest-mlogloss:0.526794\n",
      "[510]\ttrain-mlogloss:0.460375\ttest-mlogloss:0.526447\n",
      "[520]\ttrain-mlogloss:0.458964\ttest-mlogloss:0.525944\n",
      "[530]\ttrain-mlogloss:0.457686\ttest-mlogloss:0.525441\n",
      "[540]\ttrain-mlogloss:0.456251\ttest-mlogloss:0.524972\n",
      "[550]\ttrain-mlogloss:0.454981\ttest-mlogloss:0.524595\n",
      "[560]\ttrain-mlogloss:0.453541\ttest-mlogloss:0.524141\n",
      "[570]\ttrain-mlogloss:0.452441\ttest-mlogloss:0.523821\n",
      "[580]\ttrain-mlogloss:0.451433\ttest-mlogloss:0.523573\n",
      "[590]\ttrain-mlogloss:0.45028\ttest-mlogloss:0.523238\n",
      "[600]\ttrain-mlogloss:0.449129\ttest-mlogloss:0.522944\n",
      "[610]\ttrain-mlogloss:0.447983\ttest-mlogloss:0.522598\n",
      "[620]\ttrain-mlogloss:0.446987\ttest-mlogloss:0.522349\n",
      "[630]\ttrain-mlogloss:0.445695\ttest-mlogloss:0.522022\n",
      "[640]\ttrain-mlogloss:0.444623\ttest-mlogloss:0.521707\n",
      "[650]\ttrain-mlogloss:0.443689\ttest-mlogloss:0.521471\n",
      "[660]\ttrain-mlogloss:0.442577\ttest-mlogloss:0.521219\n",
      "[670]\ttrain-mlogloss:0.441635\ttest-mlogloss:0.520992\n",
      "[680]\ttrain-mlogloss:0.440711\ttest-mlogloss:0.520811\n",
      "[690]\ttrain-mlogloss:0.439781\ttest-mlogloss:0.520544\n",
      "[700]\ttrain-mlogloss:0.438946\ttest-mlogloss:0.520403\n",
      "[710]\ttrain-mlogloss:0.438064\ttest-mlogloss:0.520182\n",
      "[720]\ttrain-mlogloss:0.437167\ttest-mlogloss:0.520007\n",
      "[730]\ttrain-mlogloss:0.436369\ttest-mlogloss:0.519853\n",
      "[740]\ttrain-mlogloss:0.435416\ttest-mlogloss:0.519691\n",
      "[750]\ttrain-mlogloss:0.43456\ttest-mlogloss:0.51952\n",
      "[760]\ttrain-mlogloss:0.433615\ttest-mlogloss:0.519314\n",
      "[770]\ttrain-mlogloss:0.432859\ttest-mlogloss:0.51918\n",
      "[780]\ttrain-mlogloss:0.432142\ttest-mlogloss:0.518972\n",
      "[790]\ttrain-mlogloss:0.431345\ttest-mlogloss:0.518801\n",
      "[800]\ttrain-mlogloss:0.430444\ttest-mlogloss:0.518636\n",
      "[810]\ttrain-mlogloss:0.429794\ttest-mlogloss:0.518471\n",
      "[820]\ttrain-mlogloss:0.429111\ttest-mlogloss:0.518351\n",
      "[830]\ttrain-mlogloss:0.428318\ttest-mlogloss:0.518235\n",
      "[840]\ttrain-mlogloss:0.427622\ttest-mlogloss:0.518102\n",
      "[850]\ttrain-mlogloss:0.426827\ttest-mlogloss:0.518001\n",
      "[860]\ttrain-mlogloss:0.426087\ttest-mlogloss:0.517848\n",
      "[870]\ttrain-mlogloss:0.425372\ttest-mlogloss:0.517699\n",
      "[880]\ttrain-mlogloss:0.424561\ttest-mlogloss:0.517568\n",
      "[890]\ttrain-mlogloss:0.423917\ttest-mlogloss:0.517435\n",
      "[900]\ttrain-mlogloss:0.423264\ttest-mlogloss:0.51726\n",
      "[910]\ttrain-mlogloss:0.422747\ttest-mlogloss:0.517149\n",
      "[920]\ttrain-mlogloss:0.422063\ttest-mlogloss:0.517008\n",
      "[930]\ttrain-mlogloss:0.421419\ttest-mlogloss:0.516913\n",
      "[940]\ttrain-mlogloss:0.420628\ttest-mlogloss:0.516721\n",
      "[950]\ttrain-mlogloss:0.419932\ttest-mlogloss:0.516575\n",
      "[960]\ttrain-mlogloss:0.419328\ttest-mlogloss:0.516537\n",
      "[970]\ttrain-mlogloss:0.418707\ttest-mlogloss:0.516463\n",
      "[980]\ttrain-mlogloss:0.418003\ttest-mlogloss:0.516314\n",
      "[990]\ttrain-mlogloss:0.417445\ttest-mlogloss:0.516219\n",
      "[1000]\ttrain-mlogloss:0.416789\ttest-mlogloss:0.516101\n",
      "[1010]\ttrain-mlogloss:0.415957\ttest-mlogloss:0.515982\n",
      "[1020]\ttrain-mlogloss:0.415442\ttest-mlogloss:0.515961\n",
      "[1030]\ttrain-mlogloss:0.414795\ttest-mlogloss:0.515915\n",
      "[1040]\ttrain-mlogloss:0.414222\ttest-mlogloss:0.515898\n",
      "[1050]\ttrain-mlogloss:0.413557\ttest-mlogloss:0.515856\n",
      "[1060]\ttrain-mlogloss:0.412757\ttest-mlogloss:0.515759\n",
      "[1070]\ttrain-mlogloss:0.41201\ttest-mlogloss:0.515672\n",
      "[1080]\ttrain-mlogloss:0.411463\ttest-mlogloss:0.515567\n",
      "[1090]\ttrain-mlogloss:0.410902\ttest-mlogloss:0.515469\n",
      "[1100]\ttrain-mlogloss:0.410295\ttest-mlogloss:0.515361\n",
      "[1110]\ttrain-mlogloss:0.409398\ttest-mlogloss:0.515247\n",
      "[1120]\ttrain-mlogloss:0.408761\ttest-mlogloss:0.515152\n",
      "[1130]\ttrain-mlogloss:0.408125\ttest-mlogloss:0.515074\n",
      "[1140]\ttrain-mlogloss:0.407568\ttest-mlogloss:0.515012\n",
      "[1150]\ttrain-mlogloss:0.406984\ttest-mlogloss:0.51492\n",
      "[1160]\ttrain-mlogloss:0.406488\ttest-mlogloss:0.514861\n",
      "[1170]\ttrain-mlogloss:0.406016\ttest-mlogloss:0.51484\n",
      "[1180]\ttrain-mlogloss:0.405575\ttest-mlogloss:0.514782\n",
      "[1190]\ttrain-mlogloss:0.40489\ttest-mlogloss:0.514688\n",
      "[1200]\ttrain-mlogloss:0.404336\ttest-mlogloss:0.514611\n",
      "[1210]\ttrain-mlogloss:0.40373\ttest-mlogloss:0.514526\n",
      "[1220]\ttrain-mlogloss:0.403051\ttest-mlogloss:0.51447\n",
      "[1230]\ttrain-mlogloss:0.402467\ttest-mlogloss:0.514367\n",
      "[1240]\ttrain-mlogloss:0.401891\ttest-mlogloss:0.514313\n",
      "[1250]\ttrain-mlogloss:0.401386\ttest-mlogloss:0.514274\n",
      "[1260]\ttrain-mlogloss:0.400971\ttest-mlogloss:0.514198\n",
      "[1270]\ttrain-mlogloss:0.400334\ttest-mlogloss:0.51413\n",
      "[1280]\ttrain-mlogloss:0.399796\ttest-mlogloss:0.514077\n",
      "[1290]\ttrain-mlogloss:0.39923\ttest-mlogloss:0.514013\n",
      "[1300]\ttrain-mlogloss:0.398684\ttest-mlogloss:0.513986\n",
      "[1310]\ttrain-mlogloss:0.39814\ttest-mlogloss:0.513934\n",
      "[1320]\ttrain-mlogloss:0.397613\ttest-mlogloss:0.51394\n",
      "[1330]\ttrain-mlogloss:0.397114\ttest-mlogloss:0.513895\n",
      "[1340]\ttrain-mlogloss:0.396547\ttest-mlogloss:0.513859\n",
      "[1350]\ttrain-mlogloss:0.395987\ttest-mlogloss:0.513786\n",
      "[1360]\ttrain-mlogloss:0.395556\ttest-mlogloss:0.513785\n",
      "[1370]\ttrain-mlogloss:0.394976\ttest-mlogloss:0.513732\n",
      "[1380]\ttrain-mlogloss:0.394652\ttest-mlogloss:0.513713\n",
      "[1390]\ttrain-mlogloss:0.393951\ttest-mlogloss:0.513669\n",
      "[1400]\ttrain-mlogloss:0.393506\ttest-mlogloss:0.513601\n",
      "[1410]\ttrain-mlogloss:0.392863\ttest-mlogloss:0.513518\n",
      "[1420]\ttrain-mlogloss:0.392373\ttest-mlogloss:0.513415\n",
      "[1430]\ttrain-mlogloss:0.391896\ttest-mlogloss:0.513399\n",
      "[1440]\ttrain-mlogloss:0.39152\ttest-mlogloss:0.513359\n",
      "[1450]\ttrain-mlogloss:0.391152\ttest-mlogloss:0.513295\n",
      "[1460]\ttrain-mlogloss:0.390703\ttest-mlogloss:0.51326\n",
      "[1470]\ttrain-mlogloss:0.390437\ttest-mlogloss:0.513247\n",
      "[1480]\ttrain-mlogloss:0.389938\ttest-mlogloss:0.513213\n",
      "[1490]\ttrain-mlogloss:0.389404\ttest-mlogloss:0.513142\n",
      "[1500]\ttrain-mlogloss:0.388895\ttest-mlogloss:0.513112\n",
      "[1510]\ttrain-mlogloss:0.388528\ttest-mlogloss:0.51306\n",
      "[1520]\ttrain-mlogloss:0.387882\ttest-mlogloss:0.512973\n",
      "[1530]\ttrain-mlogloss:0.387455\ttest-mlogloss:0.512977\n",
      "[1540]\ttrain-mlogloss:0.387045\ttest-mlogloss:0.512924\n",
      "[1550]\ttrain-mlogloss:0.386548\ttest-mlogloss:0.512925\n",
      "[1560]\ttrain-mlogloss:0.386132\ttest-mlogloss:0.51288\n",
      "[1570]\ttrain-mlogloss:0.385779\ttest-mlogloss:0.512867\n",
      "[1580]\ttrain-mlogloss:0.38522\ttest-mlogloss:0.512784\n",
      "[1590]\ttrain-mlogloss:0.384677\ttest-mlogloss:0.512775\n",
      "[1600]\ttrain-mlogloss:0.384356\ttest-mlogloss:0.512743\n",
      "[1610]\ttrain-mlogloss:0.384062\ttest-mlogloss:0.512708\n",
      "[1620]\ttrain-mlogloss:0.38368\ttest-mlogloss:0.512692\n",
      "[1630]\ttrain-mlogloss:0.383124\ttest-mlogloss:0.512649\n",
      "[1640]\ttrain-mlogloss:0.382835\ttest-mlogloss:0.512622\n",
      "[1650]\ttrain-mlogloss:0.38248\ttest-mlogloss:0.51258\n",
      "[1660]\ttrain-mlogloss:0.381932\ttest-mlogloss:0.512552\n",
      "[1670]\ttrain-mlogloss:0.381458\ttest-mlogloss:0.512485\n",
      "[1680]\ttrain-mlogloss:0.380801\ttest-mlogloss:0.512432\n",
      "[1690]\ttrain-mlogloss:0.380448\ttest-mlogloss:0.512398\n",
      "[1700]\ttrain-mlogloss:0.379984\ttest-mlogloss:0.512396\n",
      "[1710]\ttrain-mlogloss:0.379673\ttest-mlogloss:0.512403\n",
      "Stopping. Best iteration:\n",
      "[1696]\ttrain-mlogloss:0.380142\ttest-mlogloss:0.51237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "import graphlab\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "print('beginning processing....')\n",
    "\n",
    "train_abc = pd.read_json(\"~/Downloads/train.json\")[['street_address','display_address']]\n",
    "test_abc  = pd.read_json(\"~/Downloads/test.json\")[['street_address','display_address']]\n",
    "tt_abc = train_abc.append(test_abc)\n",
    "levestein_distance = []\n",
    "cosine_distance  = []\n",
    "street_address = np.array(tt_abc['street_address'])\n",
    "display_address = np.array(tt_abc['display_address'])\n",
    "for i in xrange(len(tt_abc)):\n",
    "    levestein_distance.append(graphlab.distances.levenshtein(street_address[i].lower(),display_address[i].lower()))\n",
    "\n",
    "\n",
    "train_df = pd.read_json(\"~/Downloads/train.json\")\n",
    "test_df = pd.read_json(\"~/Downloads/test.json\")\n",
    "image_date = pd.read_csv(\"~/Downloads/listing_image_time.csv\")\n",
    "\n",
    "\n",
    "def runXGB(train_X, train_y, test_X,test_y,test_final,feature_names=None, seed_val=321, num_rounds=2000):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.02\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 0\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 5\n",
    "    #param['subsample'] = 0.7\n",
    "    #param['colsample_bytree'] = 0.7\n",
    "    param['lambda'] = 2\n",
    "    param['alpha'] = 0.02\n",
    "    param['subsample'] = 0.8\n",
    "    param['colsample_bytree'] = 0.8\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist,verbose_eval=10,early_stopping_rounds=20)\n",
    "    \n",
    "    xgtest1 = xgb.DMatrix(test_final)\n",
    "    pred_test_y = model.predict(xgtest1)\n",
    "    return pred_test_y, model\n",
    "\n",
    "test_df[\"bathrooms\"].loc[19671] = 1.5\n",
    "test_df[\"bathrooms\"].loc[22977] = 2.0\n",
    "test_df[\"bathrooms\"].loc[63719] = 2.0\n",
    "train_df[\"price\"] = train_df[\"price\"].clip(upper=13000)\n",
    "\n",
    "train_df[\"logprice\"] = np.log(train_df[\"price\"])\n",
    "test_df[\"logprice\"] = np.log(test_df[\"price\"])\n",
    "\n",
    "train_df[\"price_t\"] =train_df[\"price\"]/train_df[\"bedrooms\"]\n",
    "test_df[\"price_t\"] = test_df[\"price\"]/test_df[\"bedrooms\"] \n",
    "\n",
    "train_df[\"room_sum\"] = train_df[\"bedrooms\"]+train_df[\"bathrooms\"] \n",
    "test_df[\"room_sum\"] = test_df[\"bedrooms\"]+test_df[\"bathrooms\"] \n",
    "\n",
    "train_df['price_per_room'] = train_df['price']/train_df['room_sum']\n",
    "test_df['price_per_room'] = test_df['price']/test_df['room_sum']\n",
    "\n",
    "train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\n",
    "test_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\n",
    "\n",
    "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "test_df[\"num_features\"] = test_df[\"features\"].apply(len)\n",
    "\n",
    "train_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "test_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "train_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\n",
    "test_df[\"created\"] = pd.to_datetime(test_df[\"created\"])\n",
    "train_df[\"created_year\"] = train_df[\"created\"].dt.year\n",
    "test_df[\"created_year\"] = test_df[\"created\"].dt.year\n",
    "train_df[\"created_month\"] = train_df[\"created\"].dt.month\n",
    "test_df[\"created_month\"] = test_df[\"created\"].dt.month\n",
    "train_df[\"created_day\"] = train_df[\"created\"].dt.day\n",
    "test_df[\"created_day\"] = test_df[\"created\"].dt.day\n",
    "train_df[\"created_hour\"] = train_df[\"created\"].dt.hour\n",
    "test_df[\"created_hour\"] = test_df[\"created\"].dt.hour\n",
    "\n",
    "train_df[\"pos\"] = train_df.longitude.round(3).astype(str) + '_' + train_df.latitude.round(3).astype(str)\n",
    "test_df[\"pos\"] = test_df.longitude.round(3).astype(str) + '_' + test_df.latitude.round(3).astype(str)\n",
    "\n",
    "image_date.columns = [\"listing_id\", \"time_stamp\"]\n",
    "image_date.loc[80240,\"time_stamp\"] = 1478129766 \n",
    "\n",
    "image_date[\"img_date\"]                  = pd.to_datetime(image_date[\"time_stamp\"], unit=\"s\")\n",
    "image_date[\"img_days_passed\"]           = (image_date[\"img_date\"].max() - image_date[\"img_date\"]).astype(\"timedelta64[D]\").astype(int)\n",
    "image_date[\"img_date_month\"]            = image_date[\"img_date\"].dt.month\n",
    "image_date[\"img_date_week\"]             = image_date[\"img_date\"].dt.week\n",
    "image_date[\"img_date_day\"]              = image_date[\"img_date\"].dt.day\n",
    "image_date[\"img_date_dayofweek\"]        = image_date[\"img_date\"].dt.dayofweek\n",
    "image_date[\"img_date_dayofyear\"]        = image_date[\"img_date\"].dt.dayofyear\n",
    "image_date[\"img_date_hour\"]             = image_date[\"img_date\"].dt.hour\n",
    "image_date[\"img_date_monthBeginMidEnd\"] = image_date[\"img_date_day\"].apply(lambda x: 1 if x<10 else 2 if x<20 else 3)\n",
    "\n",
    "train_df = pd.merge(train_df, image_date, on=\"listing_id\", how=\"left\")\n",
    "test_df = pd.merge(test_df, image_date, on=\"listing_id\", how=\"left\")\n",
    "print('Checkpoint-1')\n",
    "\n",
    "import math\n",
    "def cart2rho(x, y):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    return rho\n",
    "\n",
    "\n",
    "def cart2phi(x, y):\n",
    "    phi = np.arctan2(y, x)\n",
    "    return phi\n",
    "\n",
    "\n",
    "def rotation_x(row, alpha):\n",
    "    x = row['latitude']\n",
    "    y = row['longitude']\n",
    "    return x*math.cos(alpha) + y*math.sin(alpha)\n",
    "\n",
    "\n",
    "def rotation_y(row, alpha):\n",
    "    x = row['latitude']\n",
    "    y = row['longitude']\n",
    "    return y*math.cos(alpha) - x*math.sin(alpha)\n",
    "\n",
    "\n",
    "def add_rotation(degrees, df):\n",
    "    namex = \"rot\" + str(degrees) + \"_X\"\n",
    "    namey = \"rot\" + str(degrees) + \"_Y\"\n",
    "\n",
    "    df['num_' + namex] = df.apply(lambda row: rotation_x(row, math.pi/(180/degrees)), axis=1)\n",
    "    df['num_' + namey] = df.apply(lambda row: rotation_y(row, math.pi/(180/degrees)), axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def operate_on_coordinates(tr_df, te_df):\n",
    "    for df in [tr_df, te_df]:\n",
    "        #polar coordinates system\n",
    "        df[\"num_rho\"] = df.apply(lambda x: cart2rho(x[\"latitude\"] - 40.78222222, x[\"longitude\"]+73.96527777), axis=1)\n",
    "        df[\"num_phi\"] = df.apply(lambda x: cart2phi(x[\"latitude\"] - 40.78222222, x[\"longitude\"]+73.96527777), axis=1)\n",
    "        #rotations\n",
    "        for angle in [15,30,45,60]:\n",
    "            df = add_rotation(angle, df)\n",
    "\n",
    "    return tr_df, te_df\n",
    "\n",
    "train_df, test_df = operate_on_coordinates(train_df, test_df)\n",
    "\n",
    "import re\n",
    "\n",
    "def cap_share(x):\n",
    "    return sum(1 for c in x if c.isupper())/float(len(x)+1)\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    # do you think that users might feel annoyed BY A DESCRIPTION THAT IS SHOUTING AT THEM?\n",
    "    df['num_cap_share'] = df['description'].apply(cap_share)\n",
    "    \n",
    "    # how long in lines the desc is?\n",
    "    df['num_nr_of_lines'] = df['description'].apply(lambda x: x.count('<br /><br />'))\n",
    "   \n",
    "    # is the description redacted by the website?        \n",
    "    df['num_redacted'] = 0\n",
    "    df['num_redacted'].ix[df['description'].str.contains('website_redacted')] = 1\n",
    "\n",
    "    \n",
    "    # can we contact someone via e-mail to ask for the details?\n",
    "    df['num_email'] = 0\n",
    "    df['num_email'].ix[df['description'].str.contains('@')] = 1\n",
    "    \n",
    "    #and... can we call them?\n",
    "    \n",
    "    reg = re.compile(\".*?(\\(?\\d{3}\\D{0,3}\\d{3}\\D{0,3}\\d{4}).*?\", re.S)\n",
    "    def try_and_find_nr(description):\n",
    "        if reg.match(description) is None:\n",
    "            return 0\n",
    "        return 1\n",
    "\n",
    "    df['num_phone_nr'] = df['description'].apply(try_and_find_nr)\n",
    "\n",
    "\n",
    "\n",
    "## latitude longitude cluster code begins \n",
    "def get_centermost_point(cluster):\n",
    "    centroid = (MultiPoint(cluster).centroid.x, MultiPoint(cluster).centroid.y)\n",
    "    centermost_point = min(cluster, key=lambda point: great_circle(point, centroid).m)\n",
    "    return tuple(centermost_point)\n",
    "\n",
    "print(len(train_df))\n",
    "print(len(test_df))\n",
    "coords = train_df.as_matrix(columns=['latitude', 'longitude'])\n",
    "coords1 = test_df.as_matrix(columns=['latitude', 'longitude'])\n",
    "kms_per_radian = 6371.0088\n",
    "epsilon = 1.5 / kms_per_radian\n",
    "db = DBSCAN(eps=epsilon, min_samples=1, algorithm='ball_tree', metric='haversine').fit(np.radians(coords))\n",
    "cluster_labels = db.labels_\n",
    "num_clusters = len(set(cluster_labels))\n",
    "#clusters = pd.Series([coords[cluster_labels == n] for n in range(num_clusters)])\n",
    "#print('Number of clusters: {}'.format(num_clusters))\n",
    "#centermost_points = clusters.map(get_centermost_point)\n",
    "#lats, lons = zip(*centermost_points)\n",
    "#rep_points = pd.DataFrame({'lon':lons, 'lat':lats})\n",
    "print('Checkpoint-2')\n",
    "#df['cluster'] = rep_points.apply(lambda row: df[(train_df['latitude']==row['lat']) &amp;&amp; (df['lon']==row['lon'])].iloc[0], axis=1)\n",
    "train_df['cluster_labels'] = cluster_labels\n",
    "test_df['cluster_labels'] = db.fit_predict(np.radians(coords1))\n",
    "df = train_df.append(test_df)\n",
    "df['levestein_dist'] = levestein_distance\n",
    "train_df = df[0:49352]\n",
    "test_df = df[49352:]\n",
    "\n",
    "##  latitude longitude cluster code begins \n",
    "\n",
    "vals = train_df['pos'].value_counts()\n",
    "dvals = vals.to_dict()\n",
    "train_df[\"density\"] = train_df['pos'].apply(lambda x: dvals.get(x, vals.min()))\n",
    "test_df[\"density\"] = test_df['pos'].apply(lambda x: dvals.get(x, vals.min()))\n",
    "\n",
    "features_to_use=[\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\",\"price_t\",\"price_per_room\", \"logprice\", \"density\",\n",
    "\"num_photos\", \"num_features\", \"num_description_words\",\"listing_id\", \"created_year\", \"created_month\", \"created_day\", \"created_hour\",\"img_days_passed\",\"img_date_month\",\"img_date_week\",\"img_date_day\",\"img_date_dayofweek\",\"img_date_dayofyear\",\"img_date_hour\",\"img_date_monthBeginMidEnd\",\"cluster_labels\",\"levestein_dist\"]\n",
    "print('Checkpoint-3')\n",
    "\n",
    "index=list(range(train_df.shape[0]))\n",
    "random.shuffle(index)\n",
    "a=[np.nan]*len(train_df)\n",
    "b=[np.nan]*len(train_df)\n",
    "c=[np.nan]*len(train_df)\n",
    "\n",
    "for i in range(5):\n",
    "    building_level={}\n",
    "    for j in train_df['manager_id'].values:\n",
    "        building_level[j]=[0,0,0]\n",
    "    \n",
    "    test_index=index[int((i*train_df.shape[0])/5):int(((i+1)*train_df.shape[0])/5)]\n",
    "    train_index=list(set(index).difference(test_index))\n",
    "    \n",
    "    for j in train_index:\n",
    "        temp=train_df.iloc[j]\n",
    "        if temp['interest_level']=='low':\n",
    "            building_level[temp['manager_id']][0]+=1\n",
    "        if temp['interest_level']=='medium':\n",
    "            building_level[temp['manager_id']][1]+=1\n",
    "        if temp['interest_level']=='high':\n",
    "            building_level[temp['manager_id']][2]+=1\n",
    "            \n",
    "    for j in test_index:\n",
    "        temp=train_df.iloc[j]\n",
    "        if sum(building_level[temp['manager_id']])!=0:\n",
    "            a[j]=building_level[temp['manager_id']][0]*1.0/sum(building_level[temp['manager_id']])\n",
    "            b[j]=building_level[temp['manager_id']][1]*1.0/sum(building_level[temp['manager_id']])\n",
    "            c[j]=building_level[temp['manager_id']][2]*1.0/sum(building_level[temp['manager_id']])\n",
    "            \n",
    "train_df['manager_level_low']=a\n",
    "train_df['manager_level_medium']=b\n",
    "train_df['manager_level_high']=c\n",
    "\n",
    "a=[]\n",
    "b=[]\n",
    "c=[]\n",
    "building_level={}\n",
    "for j in train_df['manager_id'].values:\n",
    "    building_level[j]=[0,0,0]\n",
    "\n",
    "for j in range(train_df.shape[0]):\n",
    "    temp=train_df.iloc[j]\n",
    "    if temp['interest_level']=='low':\n",
    "        building_level[temp['manager_id']][0]+=1\n",
    "    if temp['interest_level']=='medium':\n",
    "        building_level[temp['manager_id']][1]+=1\n",
    "    if temp['interest_level']=='high':\n",
    "        building_level[temp['manager_id']][2]+=1\n",
    "\n",
    "for i in test_df['manager_id'].values:\n",
    "    if i not in building_level.keys():\n",
    "        a.append(np.nan)\n",
    "        b.append(np.nan)\n",
    "        c.append(np.nan)\n",
    "    else:\n",
    "        a.append(building_level[i][0]*1.0/sum(building_level[i]))\n",
    "        b.append(building_level[i][1]*1.0/sum(building_level[i]))\n",
    "        c.append(building_level[i][2]*1.0/sum(building_level[i]))\n",
    "test_df['manager_level_low']=a\n",
    "test_df['manager_level_medium']=b\n",
    "test_df['manager_level_high']=c\n",
    "\n",
    "features_to_use.append('manager_level_low') \n",
    "features_to_use.append('manager_level_medium') \n",
    "features_to_use.append('manager_level_high')\n",
    "\n",
    "categorical = [\"display_address\", \"manager_id\", \"building_id\",\"cluster_labels\"]\n",
    "for f in categorical:\n",
    "        if train_df[f].dtype=='object':\n",
    "            lbl = LabelEncoder()\n",
    "            lbl.fit(list(train_df[f].values) + list(test_df[f].values))\n",
    "            train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "            test_df[f] = lbl.transform(list(test_df[f].values))\n",
    "            features_to_use.append(f)\n",
    "\n",
    "train_df['features'] = train_df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "test_df['features'] = test_df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "\n",
    "tfidf = CountVectorizer(stop_words='english', max_features=200)\n",
    "tr_sparse = tfidf.fit_transform(train_df[\"features\"])\n",
    "te_sparse = tfidf.transform(test_df[\"features\"])\n",
    "\n",
    "train_X = sparse.hstack([train_df[features_to_use], tr_sparse]).tocsr()\n",
    "test_X = sparse.hstack([test_df[features_to_use], te_sparse]).tocsr()\n",
    "\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "print('Checkpoint-4')\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X,train_y, test_size=0.2, random_state=0)\n",
    "preds, model = runXGB(X_train,y_train,X_test,y_test,test_X, num_rounds=2000)\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df.to_csv(\"sub54_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_X = sparse.hstack([train_df[features_to_use], tr_sparse])\n",
    "test_X = sparse.hstack([test_df[features_to_use], te_sparse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-dd405f652720>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_yy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtrain_yy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_y' is not defined"
     ]
    }
   ],
   "source": [
    "train_yy = []\n",
    "for i in xrange(len(train_y)):\n",
    "    if train_y[i] == 0:\n",
    "        train_yy.append([1,0,0])\n",
    "    if train_y[i] == 1:\n",
    "        train_yy.append([0,1,0])\n",
    "    if train_y[i] == 2:\n",
    "        train_yy.append([0,0,1])\n",
    "\n",
    "train_yy = np.array(train_yy)\n",
    "\n",
    ",\"num_rho\",\"num_phi\",\"num_cap_share\",\"num_nr_of_lines\",\"num_redacted\",\"num_email\",\"num_phone_nr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39481 train samples\n",
      "9871 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 200)               48200     \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "feature_layer (Dense)        (None, 400)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 400)               1600      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 3)                 603       \n",
      "=================================================================\n",
      "Total params: 212,603.0\n",
      "Trainable params: 211,003.0\n",
      "Non-trainable params: 1,600.0\n",
      "_________________________________________________________________\n",
      "Train on 39481 samples, validate on 9871 samples\n",
      "Epoch 1/20\n",
      "0s - loss: 0.8637 - acc: 0.6789 - val_loss: 0.7854 - val_acc: 0.6960\n",
      "Epoch 2/20\n",
      "0s - loss: 0.7904 - acc: 0.6944 - val_loss: 0.7825 - val_acc: 0.6960\n",
      "Epoch 3/20\n",
      "0s - loss: 0.7902 - acc: 0.6944 - val_loss: 0.7825 - val_acc: 0.6960\n",
      "Epoch 4/20\n",
      "0s - loss: 0.7901 - acc: 0.6944 - val_loss: 0.7827 - val_acc: 0.6960\n",
      "Epoch 5/20\n",
      "0s - loss: 0.7902 - acc: 0.6944 - val_loss: 0.7825 - val_acc: 0.6960\n",
      "Epoch 6/20\n",
      "0s - loss: 0.7901 - acc: 0.6944 - val_loss: 0.7826 - val_acc: 0.6960\n",
      "Epoch 7/20\n",
      "0s - loss: 0.7901 - acc: 0.6944 - val_loss: 0.7826 - val_acc: 0.6960\n",
      "Epoch 8/20\n",
      "0s - loss: 0.7901 - acc: 0.6944 - val_loss: 0.7826 - val_acc: 0.6960\n",
      "Epoch 9/20\n",
      "0s - loss: 0.7901 - acc: 0.6944 - val_loss: 0.7825 - val_acc: 0.6960\n",
      "Epoch 10/20\n",
      "0s - loss: 0.7902 - acc: 0.6944 - val_loss: 0.7826 - val_acc: 0.6960\n",
      "Epoch 11/20\n",
      "0s - loss: 0.7902 - acc: 0.6944 - val_loss: 0.7826 - val_acc: 0.6960\n",
      "Epoch 12/20\n",
      "0s - loss: 0.7901 - acc: 0.6944 - val_loss: 0.7825 - val_acc: 0.6960\n",
      "Epoch 13/20\n",
      "0s - loss: 0.7901 - acc: 0.6944 - val_loss: 0.7825 - val_acc: 0.6960\n",
      "Epoch 14/20\n",
      "0s - loss: 0.7901 - acc: 0.6944 - val_loss: 0.7826 - val_acc: 0.6960\n",
      "Epoch 15/20\n",
      "0s - loss: 0.7901 - acc: 0.6944 - val_loss: 0.7826 - val_acc: 0.6960\n",
      "Epoch 16/20\n",
      "0s - loss: 0.7901 - acc: 0.6944 - val_loss: 0.7826 - val_acc: 0.6960\n",
      "Epoch 17/20\n",
      "0s - loss: 0.7901 - acc: 0.6944 - val_loss: 0.7826 - val_acc: 0.6960\n",
      "Epoch 18/20\n",
      "0s - loss: 0.7901 - acc: 0.6944 - val_loss: 0.7826 - val_acc: 0.6960\n",
      "Epoch 19/20\n",
      "0s - loss: 0.7901 - acc: 0.6944 - val_loss: 0.7825 - val_acc: 0.6960\n",
      "Epoch 20/20\n",
      "0s - loss: 0.7902 - acc: 0.6944 - val_loss: 0.7826 - val_acc: 0.6960\n",
      "Test loss: 0.782572174613\n",
      "Test accuracy: 0.695978117755\n"
     ]
    }
   ],
   "source": [
    "tx = train_X.todense()\n",
    "ts = test_X.todense()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "train_yy= np_utils.to_categorical(train_y,3)\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(tx,train_yy, test_size=0.2, random_state=79)\n",
    "\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(X1_train.shape[0], 'train samples')\n",
    "print(X1_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(200, activation='relu', input_shape=(240,)))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(400, activation='relu',name='feature_layer'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "sgd = SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=20, verbose=0),\n",
    "        ]\n",
    "\n",
    "model.fit(X1_train, y1_train, batch_size=batch_size, nb_epoch=epochs,\n",
    "              shuffle=True, verbose=2, validation_data=(X1_test,y1_test),\n",
    "              callbacks=callbacks)\n",
    "\n",
    "score = model.evaluate(X1_test, y1_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "output = model.predict(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07686947,  0.22053415,  0.70259643],\n",
       "       [ 0.07686947,  0.22053415,  0.70259643],\n",
       "       [ 0.07686947,  0.22053415,  0.70259643],\n",
       "       ..., \n",
       "       [ 0.07686947,  0.22053415,  0.70259643],\n",
       "       [ 0.07686947,  0.22053415,  0.70259643],\n",
       "       [ 0.07686947,  0.22053415,  0.70259643]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "out_old = np.array(out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "out_df['high_1'] = output[:,0]\n",
    "out_df['medium_1'] = output[:,0]\n",
    "out_df['low_1'] = output[:,0]\n",
    "out_df['high'] = 0.5*(out_df['high_1'] + out_df['high'])\n",
    "out_df['medium'] = 0.5*(out_df['medium_1'] + out_df['medium'])\n",
    "out_df['low'] = 0.5*(out_df['low'] + out_df['low'])\n",
    "del out_df['low_1']\n",
    "del out_df['medium_1']\n",
    "del out_df['high_1']\n",
    "out_df.to_csv('renthop_combined.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>medium</th>\n",
       "      <th>low</th>\n",
       "      <th>listing_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.078858</td>\n",
       "      <td>0.102443</td>\n",
       "      <td>0.405260</td>\n",
       "      <td>7142618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.073002</td>\n",
       "      <td>0.073393</td>\n",
       "      <td>0.963760</td>\n",
       "      <td>7210040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073086</td>\n",
       "      <td>0.083672</td>\n",
       "      <td>0.797944</td>\n",
       "      <td>7103890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075635</td>\n",
       "      <td>0.103750</td>\n",
       "      <td>0.435925</td>\n",
       "      <td>7143442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.074189</td>\n",
       "      <td>0.086891</td>\n",
       "      <td>0.728808</td>\n",
       "      <td>6860601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.072120</td>\n",
       "      <td>0.073927</td>\n",
       "      <td>0.969322</td>\n",
       "      <td>6840081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.073142</td>\n",
       "      <td>0.085985</td>\n",
       "      <td>0.760051</td>\n",
       "      <td>6922337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.077125</td>\n",
       "      <td>0.103793</td>\n",
       "      <td>0.411403</td>\n",
       "      <td>6913616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.074059</td>\n",
       "      <td>0.095247</td>\n",
       "      <td>0.597191</td>\n",
       "      <td>6937820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.074731</td>\n",
       "      <td>0.101113</td>\n",
       "      <td>0.492569</td>\n",
       "      <td>6893933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.072244</td>\n",
       "      <td>0.072937</td>\n",
       "      <td>0.983185</td>\n",
       "      <td>6832604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.073559</td>\n",
       "      <td>0.083580</td>\n",
       "      <td>0.791868</td>\n",
       "      <td>6915282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.102032</td>\n",
       "      <td>0.474114</td>\n",
       "      <td>7127565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.072264</td>\n",
       "      <td>0.075149</td>\n",
       "      <td>0.947470</td>\n",
       "      <td>6827899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.072070</td>\n",
       "      <td>0.072210</td>\n",
       "      <td>0.997603</td>\n",
       "      <td>6934855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.072519</td>\n",
       "      <td>0.083653</td>\n",
       "      <td>0.807324</td>\n",
       "      <td>6861826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.073879</td>\n",
       "      <td>0.088463</td>\n",
       "      <td>0.708614</td>\n",
       "      <td>6871643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.072121</td>\n",
       "      <td>0.073330</td>\n",
       "      <td>0.978869</td>\n",
       "      <td>6842542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.072433</td>\n",
       "      <td>0.077080</td>\n",
       "      <td>0.913888</td>\n",
       "      <td>6934145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.078908</td>\n",
       "      <td>0.101141</td>\n",
       "      <td>0.425300</td>\n",
       "      <td>6829365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.072922</td>\n",
       "      <td>0.090918</td>\n",
       "      <td>0.684645</td>\n",
       "      <td>7167858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.072116</td>\n",
       "      <td>0.072909</td>\n",
       "      <td>0.985684</td>\n",
       "      <td>6859483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.072800</td>\n",
       "      <td>0.077174</td>\n",
       "      <td>0.906502</td>\n",
       "      <td>6861377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.074744</td>\n",
       "      <td>0.088714</td>\n",
       "      <td>0.690761</td>\n",
       "      <td>6848960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.072087</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>0.980667</td>\n",
       "      <td>6918850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.087063</td>\n",
       "      <td>0.107855</td>\n",
       "      <td>0.187400</td>\n",
       "      <td>6916867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.072856</td>\n",
       "      <td>0.084815</td>\n",
       "      <td>0.783336</td>\n",
       "      <td>6895840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.095171</td>\n",
       "      <td>0.087435</td>\n",
       "      <td>0.384379</td>\n",
       "      <td>6813539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.101381</td>\n",
       "      <td>0.091712</td>\n",
       "      <td>0.216600</td>\n",
       "      <td>7116900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.072142</td>\n",
       "      <td>0.072454</td>\n",
       "      <td>0.992550</td>\n",
       "      <td>6890328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74629</th>\n",
       "      <td>0.075153</td>\n",
       "      <td>0.102660</td>\n",
       "      <td>0.461082</td>\n",
       "      <td>6855560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74630</th>\n",
       "      <td>0.081247</td>\n",
       "      <td>0.100536</td>\n",
       "      <td>0.397555</td>\n",
       "      <td>6816731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74631</th>\n",
       "      <td>0.072374</td>\n",
       "      <td>0.079102</td>\n",
       "      <td>0.882461</td>\n",
       "      <td>6925764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74632</th>\n",
       "      <td>0.072216</td>\n",
       "      <td>0.074803</td>\n",
       "      <td>0.953771</td>\n",
       "      <td>7139280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74633</th>\n",
       "      <td>0.072650</td>\n",
       "      <td>0.095394</td>\n",
       "      <td>0.617372</td>\n",
       "      <td>6913068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74634</th>\n",
       "      <td>0.072094</td>\n",
       "      <td>0.073634</td>\n",
       "      <td>0.974443</td>\n",
       "      <td>6828445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74635</th>\n",
       "      <td>0.080028</td>\n",
       "      <td>0.090344</td>\n",
       "      <td>0.580142</td>\n",
       "      <td>6867865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74636</th>\n",
       "      <td>0.072093</td>\n",
       "      <td>0.072890</td>\n",
       "      <td>0.986355</td>\n",
       "      <td>6820397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74637</th>\n",
       "      <td>0.077798</td>\n",
       "      <td>0.090767</td>\n",
       "      <td>0.609050</td>\n",
       "      <td>6852197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74638</th>\n",
       "      <td>0.077023</td>\n",
       "      <td>0.095477</td>\n",
       "      <td>0.546081</td>\n",
       "      <td>7122934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74639</th>\n",
       "      <td>0.072075</td>\n",
       "      <td>0.072471</td>\n",
       "      <td>0.993348</td>\n",
       "      <td>6907838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74640</th>\n",
       "      <td>0.072073</td>\n",
       "      <td>0.072341</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>6865896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74641</th>\n",
       "      <td>0.074252</td>\n",
       "      <td>0.092248</td>\n",
       "      <td>0.642085</td>\n",
       "      <td>6840250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74642</th>\n",
       "      <td>0.072655</td>\n",
       "      <td>0.077370</td>\n",
       "      <td>0.905677</td>\n",
       "      <td>6926011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74643</th>\n",
       "      <td>0.072478</td>\n",
       "      <td>0.080163</td>\n",
       "      <td>0.863816</td>\n",
       "      <td>6893100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74644</th>\n",
       "      <td>0.072077</td>\n",
       "      <td>0.072458</td>\n",
       "      <td>0.993511</td>\n",
       "      <td>6867538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74645</th>\n",
       "      <td>0.088336</td>\n",
       "      <td>0.099669</td>\n",
       "      <td>0.298002</td>\n",
       "      <td>6884360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74646</th>\n",
       "      <td>0.079681</td>\n",
       "      <td>0.106887</td>\n",
       "      <td>0.320995</td>\n",
       "      <td>6903964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74647</th>\n",
       "      <td>0.076420</td>\n",
       "      <td>0.090936</td>\n",
       "      <td>0.628389</td>\n",
       "      <td>6907851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74648</th>\n",
       "      <td>0.075340</td>\n",
       "      <td>0.097666</td>\n",
       "      <td>0.537997</td>\n",
       "      <td>7211166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74649</th>\n",
       "      <td>0.091761</td>\n",
       "      <td>0.104280</td>\n",
       "      <td>0.169437</td>\n",
       "      <td>6844290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74650</th>\n",
       "      <td>0.088944</td>\n",
       "      <td>0.105552</td>\n",
       "      <td>0.194145</td>\n",
       "      <td>6947597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74651</th>\n",
       "      <td>0.072099</td>\n",
       "      <td>0.076796</td>\n",
       "      <td>0.923771</td>\n",
       "      <td>6895423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74652</th>\n",
       "      <td>0.074255</td>\n",
       "      <td>0.075250</td>\n",
       "      <td>0.913995</td>\n",
       "      <td>6812077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74653</th>\n",
       "      <td>0.072067</td>\n",
       "      <td>0.072109</td>\n",
       "      <td>0.999273</td>\n",
       "      <td>6903956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74654</th>\n",
       "      <td>0.073840</td>\n",
       "      <td>0.089451</td>\n",
       "      <td>0.693425</td>\n",
       "      <td>6881005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74655</th>\n",
       "      <td>0.072073</td>\n",
       "      <td>0.072139</td>\n",
       "      <td>0.998691</td>\n",
       "      <td>6835379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74656</th>\n",
       "      <td>0.079412</td>\n",
       "      <td>0.096961</td>\n",
       "      <td>0.484104</td>\n",
       "      <td>6882352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74657</th>\n",
       "      <td>0.089305</td>\n",
       "      <td>0.110323</td>\n",
       "      <td>0.112033</td>\n",
       "      <td>6884758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74658</th>\n",
       "      <td>0.072572</td>\n",
       "      <td>0.079308</td>\n",
       "      <td>0.876002</td>\n",
       "      <td>6924212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74659 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           high    medium       low  listing_id\n",
       "0      0.078858  0.102443  0.405260     7142618\n",
       "1      0.073002  0.073393  0.963760     7210040\n",
       "2      0.073086  0.083672  0.797944     7103890\n",
       "3      0.075635  0.103750  0.435925     7143442\n",
       "4      0.074189  0.086891  0.728808     6860601\n",
       "5      0.072120  0.073927  0.969322     6840081\n",
       "6      0.073142  0.085985  0.760051     6922337\n",
       "7      0.077125  0.103793  0.411403     6913616\n",
       "8      0.074059  0.095247  0.597191     6937820\n",
       "9      0.074731  0.101113  0.492569     6893933\n",
       "10     0.072244  0.072937  0.983185     6832604\n",
       "11     0.073559  0.083580  0.791868     6915282\n",
       "12     0.074966  0.102032  0.474114     7127565\n",
       "13     0.072264  0.075149  0.947470     6827899\n",
       "14     0.072070  0.072210  0.997603     6934855\n",
       "15     0.072519  0.083653  0.807324     6861826\n",
       "16     0.073879  0.088463  0.708614     6871643\n",
       "17     0.072121  0.073330  0.978869     6842542\n",
       "18     0.072433  0.077080  0.913888     6934145\n",
       "19     0.078908  0.101141  0.425300     6829365\n",
       "20     0.072922  0.090918  0.684645     7167858\n",
       "21     0.072116  0.072909  0.985684     6859483\n",
       "22     0.072800  0.077174  0.906502     6861377\n",
       "23     0.074744  0.088714  0.690761     6848960\n",
       "24     0.072087  0.073252  0.980667     6918850\n",
       "25     0.087063  0.107855  0.187400     6916867\n",
       "26     0.072856  0.084815  0.783336     6895840\n",
       "27     0.095171  0.087435  0.384379     6813539\n",
       "28     0.101381  0.091712  0.216600     7116900\n",
       "29     0.072142  0.072454  0.992550     6890328\n",
       "...         ...       ...       ...         ...\n",
       "74629  0.075153  0.102660  0.461082     6855560\n",
       "74630  0.081247  0.100536  0.397555     6816731\n",
       "74631  0.072374  0.079102  0.882461     6925764\n",
       "74632  0.072216  0.074803  0.953771     7139280\n",
       "74633  0.072650  0.095394  0.617372     6913068\n",
       "74634  0.072094  0.073634  0.974443     6828445\n",
       "74635  0.080028  0.090344  0.580142     6867865\n",
       "74636  0.072093  0.072890  0.986355     6820397\n",
       "74637  0.077798  0.090767  0.609050     6852197\n",
       "74638  0.077023  0.095477  0.546081     7122934\n",
       "74639  0.072075  0.072471  0.993348     6907838\n",
       "74640  0.072073  0.072341  0.995455     6865896\n",
       "74641  0.074252  0.092248  0.642085     6840250\n",
       "74642  0.072655  0.077370  0.905677     6926011\n",
       "74643  0.072478  0.080163  0.863816     6893100\n",
       "74644  0.072077  0.072458  0.993511     6867538\n",
       "74645  0.088336  0.099669  0.298002     6884360\n",
       "74646  0.079681  0.106887  0.320995     6903964\n",
       "74647  0.076420  0.090936  0.628389     6907851\n",
       "74648  0.075340  0.097666  0.537997     7211166\n",
       "74649  0.091761  0.104280  0.169437     6844290\n",
       "74650  0.088944  0.105552  0.194145     6947597\n",
       "74651  0.072099  0.076796  0.923771     6895423\n",
       "74652  0.074255  0.075250  0.913995     6812077\n",
       "74653  0.072067  0.072109  0.999273     6903956\n",
       "74654  0.073840  0.089451  0.693425     6881005\n",
       "74655  0.072073  0.072139  0.998691     6835379\n",
       "74656  0.079412  0.096961  0.484104     6882352\n",
       "74657  0.089305  0.110323  0.112033     6884758\n",
       "74658  0.072572  0.079308  0.876002     6924212\n",
       "\n",
       "[74659 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49352\n",
      "74659\n",
      "Number of clusters: 107\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from geopy.distance import great_circle\n",
    "from shapely.geometry import MultiPoint\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>medium</th>\n",
       "      <th>low</th>\n",
       "      <th>listing_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.174651</td>\n",
       "      <td>0.677637</td>\n",
       "      <td>0.147711</td>\n",
       "      <td>7142618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020473</td>\n",
       "      <td>0.022587</td>\n",
       "      <td>0.956940</td>\n",
       "      <td>7210040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014333</td>\n",
       "      <td>0.273138</td>\n",
       "      <td>0.712530</td>\n",
       "      <td>7103890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151483</td>\n",
       "      <td>0.563975</td>\n",
       "      <td>0.284542</td>\n",
       "      <td>7143442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.057541</td>\n",
       "      <td>0.274988</td>\n",
       "      <td>0.667471</td>\n",
       "      <td>6860601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.026639</td>\n",
       "      <td>0.972519</td>\n",
       "      <td>6840081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.019735</td>\n",
       "      <td>0.230524</td>\n",
       "      <td>0.749741</td>\n",
       "      <td>6922337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.081800</td>\n",
       "      <td>0.580989</td>\n",
       "      <td>0.337211</td>\n",
       "      <td>6913616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.044385</td>\n",
       "      <td>0.364165</td>\n",
       "      <td>0.591450</td>\n",
       "      <td>6937820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.050476</td>\n",
       "      <td>0.496974</td>\n",
       "      <td>0.452550</td>\n",
       "      <td>6893933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.013782</td>\n",
       "      <td>0.983440</td>\n",
       "      <td>6832604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.024908</td>\n",
       "      <td>0.116501</td>\n",
       "      <td>0.858591</td>\n",
       "      <td>6915282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.095167</td>\n",
       "      <td>0.737638</td>\n",
       "      <td>0.167195</td>\n",
       "      <td>7127565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.009561</td>\n",
       "      <td>0.055323</td>\n",
       "      <td>0.935116</td>\n",
       "      <td>6827899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.998024</td>\n",
       "      <td>6934855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.010775</td>\n",
       "      <td>0.209508</td>\n",
       "      <td>0.779717</td>\n",
       "      <td>6861826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.035522</td>\n",
       "      <td>0.218260</td>\n",
       "      <td>0.746217</td>\n",
       "      <td>6871643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.021098</td>\n",
       "      <td>0.977270</td>\n",
       "      <td>6842542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.007971</td>\n",
       "      <td>0.098422</td>\n",
       "      <td>0.893607</td>\n",
       "      <td>6934145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.084886</td>\n",
       "      <td>0.429791</td>\n",
       "      <td>0.485323</td>\n",
       "      <td>6829365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.024894</td>\n",
       "      <td>0.650789</td>\n",
       "      <td>0.324317</td>\n",
       "      <td>7167858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.017504</td>\n",
       "      <td>0.980736</td>\n",
       "      <td>6859483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.012309</td>\n",
       "      <td>0.059636</td>\n",
       "      <td>0.928055</td>\n",
       "      <td>6861377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.071754</td>\n",
       "      <td>0.282094</td>\n",
       "      <td>0.646152</td>\n",
       "      <td>6848960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.013310</td>\n",
       "      <td>0.986047</td>\n",
       "      <td>6918850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.223319</td>\n",
       "      <td>0.604039</td>\n",
       "      <td>0.172642</td>\n",
       "      <td>6916867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.022375</td>\n",
       "      <td>0.212877</td>\n",
       "      <td>0.764748</td>\n",
       "      <td>6895840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.312850</td>\n",
       "      <td>0.213896</td>\n",
       "      <td>0.473255</td>\n",
       "      <td>6813539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.730404</td>\n",
       "      <td>0.243235</td>\n",
       "      <td>0.026360</td>\n",
       "      <td>7116900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.008449</td>\n",
       "      <td>0.989595</td>\n",
       "      <td>6890328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74629</th>\n",
       "      <td>0.074840</td>\n",
       "      <td>0.475631</td>\n",
       "      <td>0.449530</td>\n",
       "      <td>6855560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74630</th>\n",
       "      <td>0.189789</td>\n",
       "      <td>0.431276</td>\n",
       "      <td>0.378935</td>\n",
       "      <td>6816731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74631</th>\n",
       "      <td>0.005993</td>\n",
       "      <td>0.130994</td>\n",
       "      <td>0.863013</td>\n",
       "      <td>6925764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74632</th>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.029069</td>\n",
       "      <td>0.969360</td>\n",
       "      <td>7139280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74633</th>\n",
       "      <td>0.010017</td>\n",
       "      <td>0.387934</td>\n",
       "      <td>0.602048</td>\n",
       "      <td>6913068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74634</th>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.017762</td>\n",
       "      <td>0.981683</td>\n",
       "      <td>6828445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74635</th>\n",
       "      <td>0.158635</td>\n",
       "      <td>0.302230</td>\n",
       "      <td>0.539135</td>\n",
       "      <td>6867865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74636</th>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.014538</td>\n",
       "      <td>0.984763</td>\n",
       "      <td>6820397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74637</th>\n",
       "      <td>0.050101</td>\n",
       "      <td>0.370482</td>\n",
       "      <td>0.579417</td>\n",
       "      <td>6852197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74638</th>\n",
       "      <td>0.146959</td>\n",
       "      <td>0.629647</td>\n",
       "      <td>0.223395</td>\n",
       "      <td>7122934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74639</th>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>0.996002</td>\n",
       "      <td>6907838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74640</th>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>0.995378</td>\n",
       "      <td>6865896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74641</th>\n",
       "      <td>0.054955</td>\n",
       "      <td>0.254896</td>\n",
       "      <td>0.690149</td>\n",
       "      <td>6840250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74642</th>\n",
       "      <td>0.015413</td>\n",
       "      <td>0.077594</td>\n",
       "      <td>0.906994</td>\n",
       "      <td>6926011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74643</th>\n",
       "      <td>0.008485</td>\n",
       "      <td>0.197344</td>\n",
       "      <td>0.794171</td>\n",
       "      <td>6893100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74644</th>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.007227</td>\n",
       "      <td>0.992450</td>\n",
       "      <td>6867538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74645</th>\n",
       "      <td>0.250585</td>\n",
       "      <td>0.399065</td>\n",
       "      <td>0.350350</td>\n",
       "      <td>6884360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74646</th>\n",
       "      <td>0.088759</td>\n",
       "      <td>0.575715</td>\n",
       "      <td>0.335526</td>\n",
       "      <td>6903964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74647</th>\n",
       "      <td>0.066390</td>\n",
       "      <td>0.288587</td>\n",
       "      <td>0.645024</td>\n",
       "      <td>6907851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74648</th>\n",
       "      <td>0.072933</td>\n",
       "      <td>0.442241</td>\n",
       "      <td>0.484825</td>\n",
       "      <td>7211166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74649</th>\n",
       "      <td>0.360436</td>\n",
       "      <td>0.463329</td>\n",
       "      <td>0.176235</td>\n",
       "      <td>6844290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74650</th>\n",
       "      <td>0.253771</td>\n",
       "      <td>0.561423</td>\n",
       "      <td>0.184806</td>\n",
       "      <td>6947597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74651</th>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.093421</td>\n",
       "      <td>0.905838</td>\n",
       "      <td>6895423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74652</th>\n",
       "      <td>0.027208</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.945341</td>\n",
       "      <td>6812077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74653</th>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.999178</td>\n",
       "      <td>6903956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74654</th>\n",
       "      <td>0.025172</td>\n",
       "      <td>0.201376</td>\n",
       "      <td>0.773453</td>\n",
       "      <td>6881005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74655</th>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.998906</td>\n",
       "      <td>6835379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74656</th>\n",
       "      <td>0.102260</td>\n",
       "      <td>0.382613</td>\n",
       "      <td>0.515127</td>\n",
       "      <td>6882352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74657</th>\n",
       "      <td>0.280284</td>\n",
       "      <td>0.614422</td>\n",
       "      <td>0.105294</td>\n",
       "      <td>6884758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74658</th>\n",
       "      <td>0.008177</td>\n",
       "      <td>0.131551</td>\n",
       "      <td>0.860272</td>\n",
       "      <td>6924212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74659 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           high    medium       low  listing_id\n",
       "0      0.174651  0.677637  0.147711     7142618\n",
       "1      0.020473  0.022587  0.956940     7210040\n",
       "2      0.014333  0.273138  0.712530     7103890\n",
       "3      0.151483  0.563975  0.284542     7143442\n",
       "4      0.057541  0.274988  0.667471     6860601\n",
       "5      0.000842  0.026639  0.972519     6840081\n",
       "6      0.019735  0.230524  0.749741     6922337\n",
       "7      0.081800  0.580989  0.337211     6913616\n",
       "8      0.044385  0.364165  0.591450     6937820\n",
       "9      0.050476  0.496974  0.452550     6893933\n",
       "10     0.002778  0.013782  0.983440     6832604\n",
       "11     0.024908  0.116501  0.858591     6915282\n",
       "12     0.095167  0.737638  0.167195     7127565\n",
       "13     0.009561  0.055323  0.935116     6827899\n",
       "14     0.000109  0.001867  0.998024     6934855\n",
       "15     0.010775  0.209508  0.779717     6861826\n",
       "16     0.035522  0.218260  0.746217     6871643\n",
       "17     0.001632  0.021098  0.977270     6842542\n",
       "18     0.007971  0.098422  0.893607     6934145\n",
       "19     0.084886  0.429791  0.485323     6829365\n",
       "20     0.024894  0.650789  0.324317     7167858\n",
       "21     0.001760  0.017504  0.980736     6859483\n",
       "22     0.012309  0.059636  0.928055     6861377\n",
       "23     0.071754  0.282094  0.646152     6848960\n",
       "24     0.000643  0.013310  0.986047     6918850\n",
       "25     0.223319  0.604039  0.172642     6916867\n",
       "26     0.022375  0.212877  0.764748     6895840\n",
       "27     0.312850  0.213896  0.473255     6813539\n",
       "28     0.730404  0.243235  0.026360     7116900\n",
       "29     0.001956  0.008449  0.989595     6890328\n",
       "...         ...       ...       ...         ...\n",
       "74629  0.074840  0.475631  0.449530     6855560\n",
       "74630  0.189789  0.431276  0.378935     6816731\n",
       "74631  0.005993  0.130994  0.863013     6925764\n",
       "74632  0.001571  0.029069  0.969360     7139280\n",
       "74633  0.010017  0.387934  0.602048     6913068\n",
       "74634  0.000555  0.017762  0.981683     6828445\n",
       "74635  0.158635  0.302230  0.539135     6867865\n",
       "74636  0.000699  0.014538  0.984763     6820397\n",
       "74637  0.050101  0.370482  0.579417     6852197\n",
       "74638  0.146959  0.629647  0.223395     7122934\n",
       "74639  0.000288  0.003710  0.996002     6907838\n",
       "74640  0.000231  0.004391  0.995378     6865896\n",
       "74641  0.054955  0.254896  0.690149     6840250\n",
       "74642  0.015413  0.077594  0.906994     6926011\n",
       "74643  0.008485  0.197344  0.794171     6893100\n",
       "74644  0.000323  0.007227  0.992450     6867538\n",
       "74645  0.250585  0.399065  0.350350     6884360\n",
       "74646  0.088759  0.575715  0.335526     6903964\n",
       "74647  0.066390  0.288587  0.645024     6907851\n",
       "74648  0.072933  0.442241  0.484825     7211166\n",
       "74649  0.360436  0.463329  0.176235     6844290\n",
       "74650  0.253771  0.561423  0.184806     6947597\n",
       "74651  0.000741  0.093421  0.905838     6895423\n",
       "74652  0.027208  0.027451  0.945341     6812077\n",
       "74653  0.000057  0.000765  0.999178     6903956\n",
       "74654  0.025172  0.201376  0.773453     6881005\n",
       "74655  0.000189  0.000904  0.998906     6835379\n",
       "74656  0.102260  0.382613  0.515127     6882352\n",
       "74657  0.280284  0.614422  0.105294     6884758\n",
       "74658  0.008177  0.131551  0.860272     6924212\n",
       "\n",
       "[74659 rows x 4 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.7514</td>\n",
       "      <td>-73.9730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.7493</td>\n",
       "      <td>-73.7142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.7601</td>\n",
       "      <td>-73.8221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.0411</td>\n",
       "      <td>-73.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.7863</td>\n",
       "      <td>-74.0112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40.7291</td>\n",
       "      <td>-74.2224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40.5956</td>\n",
       "      <td>-73.7555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39.8395</td>\n",
       "      <td>-86.1527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40.1159</td>\n",
       "      <td>-74.6267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40.6616</td>\n",
       "      <td>-74.6637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>40.8452</td>\n",
       "      <td>-73.9809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>40.7798</td>\n",
       "      <td>-74.1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40.0450</td>\n",
       "      <td>-75.5214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>40.6759</td>\n",
       "      <td>-73.7517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>42.2019</td>\n",
       "      <td>-70.9846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>40.7917</td>\n",
       "      <td>-74.2053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>40.7902</td>\n",
       "      <td>-73.8659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>40.8362</td>\n",
       "      <td>-74.0482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>42.2509</td>\n",
       "      <td>-71.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>40.7402</td>\n",
       "      <td>-74.1571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>39.7996</td>\n",
       "      <td>-74.6248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>40.6063</td>\n",
       "      <td>-74.0604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>40.7907</td>\n",
       "      <td>-73.8032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>44.6038</td>\n",
       "      <td>-75.1773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>40.9697</td>\n",
       "      <td>-72.1336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>41.0781</td>\n",
       "      <td>-73.8601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>43.0346</td>\n",
       "      <td>-76.6336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>40.9067</td>\n",
       "      <td>-73.8147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>42.3459</td>\n",
       "      <td>-71.0794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>40.7674</td>\n",
       "      <td>-73.6445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>42.2098</td>\n",
       "      <td>-71.0385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>40.9346</td>\n",
       "      <td>-73.8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>42.0463</td>\n",
       "      <td>-71.2375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>40.6545</td>\n",
       "      <td>-73.7316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>40.9636</td>\n",
       "      <td>-73.8582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>41.5021</td>\n",
       "      <td>-90.5526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>31.1213</td>\n",
       "      <td>-92.0668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>41.0101</td>\n",
       "      <td>-72.1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>38.5529</td>\n",
       "      <td>-121.4880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>40.5196</td>\n",
       "      <td>-74.1964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>40.8823</td>\n",
       "      <td>-74.1434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>40.9174</td>\n",
       "      <td>-73.8385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>39.9230</td>\n",
       "      <td>-104.9850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>42.3776</td>\n",
       "      <td>-71.0526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>40.5571</td>\n",
       "      <td>-74.1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>40.5564</td>\n",
       "      <td>-73.7054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>37.9031</td>\n",
       "      <td>-65.8483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>40.9259</td>\n",
       "      <td>-74.4646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>40.6331</td>\n",
       "      <td>-74.1659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>40.8169</td>\n",
       "      <td>-74.0808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>40.7805</td>\n",
       "      <td>-73.7517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>40.7167</td>\n",
       "      <td>-74.2032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>40.9319</td>\n",
       "      <td>-77.0453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>40.5691</td>\n",
       "      <td>-74.0205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>40.7408</td>\n",
       "      <td>-74.1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>40.6031</td>\n",
       "      <td>-73.9229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>40.8002</td>\n",
       "      <td>-74.0453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>41.0534</td>\n",
       "      <td>-73.8186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>40.8295</td>\n",
       "      <td>-73.9713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat       lon\n",
       "0    40.7514  -73.9730\n",
       "1    40.7493  -73.7142\n",
       "2    40.7601  -73.8221\n",
       "3    41.0411  -73.5423\n",
       "4    40.7863  -74.0112\n",
       "5    40.7291  -74.2224\n",
       "6    40.5956  -73.7555\n",
       "7    39.8395  -86.1527\n",
       "8     0.0000    0.0000\n",
       "9    40.1159  -74.6267\n",
       "10   40.6616  -74.6637\n",
       "11   40.8452  -73.9809\n",
       "12   40.7798  -74.1215\n",
       "13   40.0450  -75.5214\n",
       "14   40.6759  -73.7517\n",
       "15   42.2019  -70.9846\n",
       "16   40.7917  -74.2053\n",
       "17   40.7902  -73.8659\n",
       "18   40.8362  -74.0482\n",
       "19   42.2509  -71.0060\n",
       "20   40.7402  -74.1571\n",
       "21   39.7996  -74.6248\n",
       "22   40.6063  -74.0604\n",
       "23   40.7907  -73.8032\n",
       "24   44.6038  -75.1773\n",
       "25   40.9697  -72.1336\n",
       "26   41.0781  -73.8601\n",
       "27   43.0346  -76.6336\n",
       "28   40.9067  -73.8147\n",
       "29   42.3459  -71.0794\n",
       "..       ...       ...\n",
       "77   40.7674  -73.6445\n",
       "78   42.2098  -71.0385\n",
       "79   40.9346  -73.8999\n",
       "80   42.0463  -71.2375\n",
       "81   40.6545  -73.7316\n",
       "82   40.9636  -73.8582\n",
       "83   41.5021  -90.5526\n",
       "84   31.1213  -92.0668\n",
       "85   41.0101  -72.1958\n",
       "86   38.5529 -121.4880\n",
       "87   40.5196  -74.1964\n",
       "88   40.8823  -74.1434\n",
       "89   40.9174  -73.8385\n",
       "90   39.9230 -104.9850\n",
       "91   42.3776  -71.0526\n",
       "92   40.5571  -74.1410\n",
       "93   40.5564  -73.7054\n",
       "94   37.9031  -65.8483\n",
       "95   40.9259  -74.4646\n",
       "96   40.6331  -74.1659\n",
       "97   40.8169  -74.0808\n",
       "98   40.7805  -73.7517\n",
       "99   40.7167  -74.2032\n",
       "100  40.9319  -77.0453\n",
       "101  40.5691  -74.0205\n",
       "102  40.7408  -74.1237\n",
       "103  40.6031  -73.9229\n",
       "104  40.8002  -74.0453\n",
       "105  41.0534  -73.8186\n",
       "106  40.8295  -73.9713\n",
       "\n",
       "[107 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        13274\n",
       "1        13391\n",
       "2          990\n",
       "3          481\n",
       "4        12317\n",
       "5        14924\n",
       "6        10056\n",
       "7        12996\n",
       "8        15294\n",
       "9        12650\n",
       "10        6813\n",
       "11        9809\n",
       "12        4111\n",
       "13       12690\n",
       "14       10876\n",
       "15       10761\n",
       "16        9652\n",
       "17         180\n",
       "18       11327\n",
       "19        2760\n",
       "20       15313\n",
       "21       10107\n",
       "22       10579\n",
       "23         864\n",
       "24       10761\n",
       "25       14430\n",
       "26       11676\n",
       "27       14467\n",
       "28       12823\n",
       "29       15001\n",
       "         ...  \n",
       "74629      339\n",
       "74630     8687\n",
       "74631    10868\n",
       "74632    15473\n",
       "74633    11131\n",
       "74634    10014\n",
       "74635     9385\n",
       "74636    13106\n",
       "74637     9185\n",
       "74638     3591\n",
       "74639    11061\n",
       "74640    12349\n",
       "74641    15313\n",
       "74642    10895\n",
       "74643    10308\n",
       "74644    14560\n",
       "74645     9367\n",
       "74646    15028\n",
       "74647    10650\n",
       "74648    11839\n",
       "74649    13058\n",
       "74650    15356\n",
       "74651    14601\n",
       "74652    15040\n",
       "74653     8494\n",
       "74654     7182\n",
       "74655     8784\n",
       "74656    15356\n",
       "74657    11108\n",
       "74658    12282\n",
       "Name: display_address, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['display_address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10661"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        12282\n",
       "1         9080\n",
       "2        13719\n",
       "3        10866\n",
       "4        15072\n",
       "5        15194\n",
       "6        14964\n",
       "7        15223\n",
       "8        11646\n",
       "9         6459\n",
       "10       15694\n",
       "11       14685\n",
       "12        9660\n",
       "13       15380\n",
       "14       10903\n",
       "15       10791\n",
       "16        2750\n",
       "17       13340\n",
       "18       14962\n",
       "19        2752\n",
       "20       12188\n",
       "21        9584\n",
       "22       10797\n",
       "23       12060\n",
       "24       13956\n",
       "25       10901\n",
       "26       10107\n",
       "27       15369\n",
       "28        1446\n",
       "29       10066\n",
       "         ...  \n",
       "49322    12579\n",
       "49323    14366\n",
       "49324    11023\n",
       "49325    12888\n",
       "49326    15464\n",
       "49327     8048\n",
       "49328    13391\n",
       "49329    14899\n",
       "49330    10635\n",
       "49331    15694\n",
       "49332    15523\n",
       "49333    15371\n",
       "49334    12499\n",
       "49335     8636\n",
       "49336    10839\n",
       "49337    10028\n",
       "49338    11088\n",
       "49339    10989\n",
       "49340    11228\n",
       "49341    11841\n",
       "49342    14310\n",
       "49343    10020\n",
       "49344     8953\n",
       "49345    11106\n",
       "49346    10579\n",
       "49347     9577\n",
       "49348    12864\n",
       "49349    15306\n",
       "49350    14850\n",
       "49351    12707\n",
       "Name: display_address, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['display_address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        12282\n",
       "1         9080\n",
       "2        13719\n",
       "3        10866\n",
       "4        15072\n",
       "5        15194\n",
       "6        14964\n",
       "7        15223\n",
       "8        11646\n",
       "9         6459\n",
       "10       15694\n",
       "11       14685\n",
       "12        9660\n",
       "13       15380\n",
       "14       10903\n",
       "15       10791\n",
       "16        2750\n",
       "17       13340\n",
       "18       14962\n",
       "19        2752\n",
       "20       12188\n",
       "21        9584\n",
       "22       10797\n",
       "23       12060\n",
       "24       13956\n",
       "25       10901\n",
       "26       10107\n",
       "27       15369\n",
       "28        1446\n",
       "29       10066\n",
       "         ...  \n",
       "49322    12579\n",
       "49323    14366\n",
       "49324    11023\n",
       "49325    12888\n",
       "49326    15464\n",
       "49327     8048\n",
       "49328    13391\n",
       "49329    14899\n",
       "49330    10635\n",
       "49331    15694\n",
       "49332    15523\n",
       "49333    15371\n",
       "49334    12499\n",
       "49335     8636\n",
       "49336    10839\n",
       "49337    10028\n",
       "49338    11088\n",
       "49339    10989\n",
       "49340    11228\n",
       "49341    11841\n",
       "49342    14310\n",
       "49343    10020\n",
       "49344     8953\n",
       "49345    11106\n",
       "49346    10579\n",
       "49347     9577\n",
       "49348    12864\n",
       "49349    15306\n",
       "49350    14850\n",
       "49351    12707\n",
       "Name: display_address, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['display_address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_abc = pd.read_json(\"~/Downloads/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "('string index out of range', u'occurred at index 100544')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-4bef68a09293>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_abc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'levestein'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_abc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgraphlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevenshtein\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'street_address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'display_address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   4150\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4151\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4152\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4154\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4246\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4247\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4248\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4249\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4250\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-4bef68a09293>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_abc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'levestein'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_abc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgraphlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevenshtein\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'street_address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'display_address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: ('string index out of range', u'occurred at index 100544')"
     ]
    }
   ],
   "source": [
    "train_abc['levestein'] = train_abc.apply(lambda row: graphlab.distances.levenshtein(row['street_address'][0],row['display_address'][0]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ToolkitError",
     "evalue": "This distance does not support the provided type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mToolkitError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-aefa994de743>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgraphlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevenshtein\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i am a good boy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i am a very good boy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgraphlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i am a good boy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i am a very good boy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/graphlab/toolkits/distances/_distances.pyc\u001b[0m in \u001b[0;36mcosine\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;36m0.13227816872537534\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \"\"\"\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_gl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlevenshtein\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/graphlab/extensions.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_make_injected_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_run_toolkit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_class_instance_from_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/graphlab/extensions.pyc\u001b[0m in \u001b[0;36m_run_toolkit_function\u001b[0;34m(fnname, arguments, args, kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_ToolkitError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0m_ToolkitError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Toolkit failed with unknown error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mToolkitError\u001b[0m: This distance does not support the provided type."
     ]
    }
   ],
   "source": [
    "import graphlab \n",
    "\n",
    "graphlab.distances.levenshtein(\"i am a good boy\", \"i am a very good boy\")\n",
    "graphlab.distances.cosine(\"i am a good boy\", \"i am a very good boy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fcce775235df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_abc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"~/Downloads/train.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'street_address'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'display_address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_abc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"~/Downloads/test.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'street_address'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'display_address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtt_abc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_abc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_abc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlevestein_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcosine_distance\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "train_abc = pd.read_json(\"~/Downloads/train.json\")[['street_address','display_address']]\n",
    "test_abc  = pd.read_json(\"~/Downloads/test.json\")[['street_address','display_address']]\n",
    "tt_abc = train_abc.append(test_abc)\n",
    "levestein_distance = []\n",
    "cosine_distance  = []\n",
    "street_address = np.array(tt_abc['street_address'])\n",
    "display_address = np.array(tt_abc['display_address'])\n",
    "for i in xrange(len(tt_abc)):\n",
    "    levestein_distance.append(graphlab.distances.levenshtein(street_address[i].lower(),display_address[i].lower()))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 15.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 16.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 7.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 11.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 7.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 21.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 7.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 15.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 13.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 11.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 7.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 18.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 19.0,\n",
       " 4.0,\n",
       " 15.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 19.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 71.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 42.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 18.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 90.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 13.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 26.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 5.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 43.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 19.0,\n",
       " 5.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 7.0,\n",
       " 4.0,\n",
       " 7.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 2.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 15.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 19.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 14.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 22.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 16.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 19.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 18.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 0.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 12.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 13.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 21.0,\n",
       " 5.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 23.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 16.0,\n",
       " 4.0,\n",
       " 34.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 7.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 12.0,\n",
       " 26.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 19.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " ...]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levestein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santanu/tensorflowGPU/lib/python2.7/site-packages/ipykernel/__main__.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/santanu/tensorflowGPU/lib/python2.7/site-packages/ipykernel/__main__.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/santanu/tensorflowGPU/lib/python2.7/site-packages/ipykernel/__main__.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/santanu/tensorflowGPU/lib/python2.7/site-packages/ipykernel/__main__.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/santanu/tensorflowGPU/lib/python2.7/site-packages/ipykernel/__main__.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/santanu/tensorflowGPU/lib/python2.7/site-packages/ipykernel/__main__.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/santanu/tensorflowGPU/lib/python2.7/site-packages/ipykernel/__main__.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/santanu/tensorflowGPU/lib/python2.7/site-packages/ipykernel/__main__.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-4056fe9efaba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0mtr_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0mte_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 839\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[1;32m    782\u001b[0m                                  \" contain stop words\")\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "location_dict = {\n",
    "'manhatten_loc' : [40.7527, -73.9943],\n",
    "'brooklyn_loc' : [45.0761,-73.9442],\n",
    "'bronx_loc' : [40.8448,-73.8648],\n",
    "'queens_loc' : [40.7282,-73.7949],\n",
    "'staten_loc' : [40.5795,-74.1502]}\n",
    "\n",
    "for location in location_dict.keys():\n",
    "\n",
    "    lat1 = train_df['latitude'].apply(radians)\n",
    "    lon1 = train_df['longitude'].apply(radians)\n",
    "    lat2 = radians(location_dict[location][0])\n",
    "    lon2 = radians(location_dict[location][1])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    def power(x):\n",
    "        return x**2\n",
    "\n",
    "    a = (dlat/2).apply(sin).apply(power) + lat1.apply(cos) * cos(lat2) * (dlon/2).apply(sin).apply(power)\n",
    "    c = 2 * a.apply(sqrt).apply(sin)\n",
    "\n",
    "    ### Add a new column called distance\n",
    "    train_df['distance_' + location] = R * c\n",
    "    features_to_use.append('distance_' + location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.08467\ttest-mlogloss:1.08482\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[10]\ttrain-mlogloss:0.972106\ttest-mlogloss:0.973233\n",
      "[20]\ttrain-mlogloss:0.886912\ttest-mlogloss:0.889152\n",
      "[30]\ttrain-mlogloss:0.821269\ttest-mlogloss:0.824471\n",
      "[40]\ttrain-mlogloss:0.7719\ttest-mlogloss:0.776105\n",
      "[50]\ttrain-mlogloss:0.7323\ttest-mlogloss:0.737616\n",
      "[60]\ttrain-mlogloss:0.701934\ttest-mlogloss:0.708262\n",
      "[70]\ttrain-mlogloss:0.677584\ttest-mlogloss:0.68496\n",
      "[80]\ttrain-mlogloss:0.657362\ttest-mlogloss:0.665795\n",
      "[90]\ttrain-mlogloss:0.639537\ttest-mlogloss:0.64918\n",
      "[100]\ttrain-mlogloss:0.624053\ttest-mlogloss:0.634789\n",
      "[110]\ttrain-mlogloss:0.610652\ttest-mlogloss:0.622472\n",
      "[120]\ttrain-mlogloss:0.598759\ttest-mlogloss:0.611913\n",
      "[130]\ttrain-mlogloss:0.588451\ttest-mlogloss:0.602725\n",
      "[140]\ttrain-mlogloss:0.579688\ttest-mlogloss:0.595097\n",
      "[150]\ttrain-mlogloss:0.572618\ttest-mlogloss:0.589001\n",
      "[160]\ttrain-mlogloss:0.565721\ttest-mlogloss:0.583255\n",
      "[170]\ttrain-mlogloss:0.559443\ttest-mlogloss:0.578035\n",
      "[180]\ttrain-mlogloss:0.553689\ttest-mlogloss:0.573309\n",
      "[190]\ttrain-mlogloss:0.548584\ttest-mlogloss:0.569228\n",
      "[200]\ttrain-mlogloss:0.543719\ttest-mlogloss:0.565472\n",
      "[210]\ttrain-mlogloss:0.539124\ttest-mlogloss:0.561948\n",
      "[220]\ttrain-mlogloss:0.535229\ttest-mlogloss:0.559065\n",
      "[230]\ttrain-mlogloss:0.531582\ttest-mlogloss:0.556461\n",
      "[240]\ttrain-mlogloss:0.527989\ttest-mlogloss:0.553924\n",
      "[250]\ttrain-mlogloss:0.524564\ttest-mlogloss:0.551647\n",
      "[260]\ttrain-mlogloss:0.521639\ttest-mlogloss:0.549688\n",
      "[270]\ttrain-mlogloss:0.518606\ttest-mlogloss:0.547862\n",
      "[280]\ttrain-mlogloss:0.515886\ttest-mlogloss:0.546168\n",
      "[290]\ttrain-mlogloss:0.513094\ttest-mlogloss:0.544537\n",
      "[300]\ttrain-mlogloss:0.510782\ttest-mlogloss:0.54313\n",
      "[310]\ttrain-mlogloss:0.508274\ttest-mlogloss:0.541602\n",
      "[320]\ttrain-mlogloss:0.505842\ttest-mlogloss:0.540201\n",
      "[330]\ttrain-mlogloss:0.503276\ttest-mlogloss:0.538761\n",
      "[340]\ttrain-mlogloss:0.501088\ttest-mlogloss:0.5376\n",
      "[350]\ttrain-mlogloss:0.498888\ttest-mlogloss:0.536393\n",
      "[360]\ttrain-mlogloss:0.496853\ttest-mlogloss:0.535355\n",
      "[370]\ttrain-mlogloss:0.494633\ttest-mlogloss:0.534365\n",
      "[380]\ttrain-mlogloss:0.492431\ttest-mlogloss:0.5334\n",
      "[390]\ttrain-mlogloss:0.490392\ttest-mlogloss:0.532572\n",
      "[400]\ttrain-mlogloss:0.488341\ttest-mlogloss:0.531645\n",
      "[410]\ttrain-mlogloss:0.48637\ttest-mlogloss:0.53071\n",
      "[420]\ttrain-mlogloss:0.484684\ttest-mlogloss:0.529983\n",
      "[430]\ttrain-mlogloss:0.483029\ttest-mlogloss:0.529337\n",
      "[440]\ttrain-mlogloss:0.481644\ttest-mlogloss:0.528576\n",
      "[450]\ttrain-mlogloss:0.480004\ttest-mlogloss:0.527851\n",
      "[460]\ttrain-mlogloss:0.478542\ttest-mlogloss:0.527158\n",
      "[470]\ttrain-mlogloss:0.476955\ttest-mlogloss:0.526538\n",
      "[480]\ttrain-mlogloss:0.475304\ttest-mlogloss:0.525811\n",
      "[490]\ttrain-mlogloss:0.473754\ttest-mlogloss:0.525159\n",
      "[500]\ttrain-mlogloss:0.47225\ttest-mlogloss:0.524543\n",
      "[510]\ttrain-mlogloss:0.470874\ttest-mlogloss:0.52399\n",
      "[520]\ttrain-mlogloss:0.469573\ttest-mlogloss:0.523532\n",
      "[530]\ttrain-mlogloss:0.468127\ttest-mlogloss:0.522988\n",
      "[540]\ttrain-mlogloss:0.466882\ttest-mlogloss:0.522493\n",
      "[550]\ttrain-mlogloss:0.465563\ttest-mlogloss:0.522079\n",
      "[560]\ttrain-mlogloss:0.464158\ttest-mlogloss:0.521606\n",
      "[570]\ttrain-mlogloss:0.462732\ttest-mlogloss:0.521134\n",
      "[580]\ttrain-mlogloss:0.461328\ttest-mlogloss:0.520739\n",
      "[590]\ttrain-mlogloss:0.460018\ttest-mlogloss:0.520381\n",
      "[600]\ttrain-mlogloss:0.45873\ttest-mlogloss:0.51999\n",
      "[610]\ttrain-mlogloss:0.457486\ttest-mlogloss:0.519634\n",
      "[620]\ttrain-mlogloss:0.45616\ttest-mlogloss:0.519264\n",
      "[630]\ttrain-mlogloss:0.454997\ttest-mlogloss:0.518879\n",
      "[640]\ttrain-mlogloss:0.453854\ttest-mlogloss:0.518582\n",
      "[650]\ttrain-mlogloss:0.452614\ttest-mlogloss:0.518229\n",
      "[660]\ttrain-mlogloss:0.451335\ttest-mlogloss:0.51781\n",
      "[670]\ttrain-mlogloss:0.450143\ttest-mlogloss:0.517494\n",
      "[680]\ttrain-mlogloss:0.449167\ttest-mlogloss:0.517268\n",
      "[690]\ttrain-mlogloss:0.447975\ttest-mlogloss:0.517002\n",
      "[700]\ttrain-mlogloss:0.446815\ttest-mlogloss:0.516747\n",
      "[710]\ttrain-mlogloss:0.445778\ttest-mlogloss:0.516447\n",
      "[720]\ttrain-mlogloss:0.444751\ttest-mlogloss:0.516201\n",
      "[730]\ttrain-mlogloss:0.443657\ttest-mlogloss:0.515922\n",
      "[740]\ttrain-mlogloss:0.442613\ttest-mlogloss:0.515653\n",
      "[750]\ttrain-mlogloss:0.441671\ttest-mlogloss:0.515436\n",
      "[760]\ttrain-mlogloss:0.440674\ttest-mlogloss:0.515174\n",
      "[770]\ttrain-mlogloss:0.439589\ttest-mlogloss:0.514937\n",
      "[780]\ttrain-mlogloss:0.438427\ttest-mlogloss:0.514676\n",
      "[790]\ttrain-mlogloss:0.437503\ttest-mlogloss:0.514493\n",
      "[800]\ttrain-mlogloss:0.436415\ttest-mlogloss:0.51428\n",
      "[810]\ttrain-mlogloss:0.435459\ttest-mlogloss:0.514019\n",
      "[820]\ttrain-mlogloss:0.434491\ttest-mlogloss:0.513881\n",
      "[830]\ttrain-mlogloss:0.433347\ttest-mlogloss:0.513737\n",
      "[840]\ttrain-mlogloss:0.43239\ttest-mlogloss:0.513578\n",
      "[850]\ttrain-mlogloss:0.43155\ttest-mlogloss:0.513412\n",
      "[860]\ttrain-mlogloss:0.430495\ttest-mlogloss:0.513232\n",
      "[870]\ttrain-mlogloss:0.429551\ttest-mlogloss:0.513088\n",
      "[880]\ttrain-mlogloss:0.428545\ttest-mlogloss:0.512926\n",
      "[890]\ttrain-mlogloss:0.427721\ttest-mlogloss:0.512807\n",
      "[900]\ttrain-mlogloss:0.426797\ttest-mlogloss:0.512693\n",
      "[910]\ttrain-mlogloss:0.425802\ttest-mlogloss:0.512546\n",
      "[920]\ttrain-mlogloss:0.424804\ttest-mlogloss:0.512371\n",
      "[930]\ttrain-mlogloss:0.42393\ttest-mlogloss:0.512279\n",
      "[940]\ttrain-mlogloss:0.423057\ttest-mlogloss:0.512149\n",
      "[950]\ttrain-mlogloss:0.422202\ttest-mlogloss:0.512\n",
      "[960]\ttrain-mlogloss:0.421365\ttest-mlogloss:0.511843\n",
      "[970]\ttrain-mlogloss:0.420459\ttest-mlogloss:0.511784\n",
      "[980]\ttrain-mlogloss:0.419543\ttest-mlogloss:0.511697\n",
      "[990]\ttrain-mlogloss:0.418677\ttest-mlogloss:0.511516\n",
      "[1000]\ttrain-mlogloss:0.417789\ttest-mlogloss:0.511346\n",
      "[1010]\ttrain-mlogloss:0.416938\ttest-mlogloss:0.511288\n",
      "[1020]\ttrain-mlogloss:0.416056\ttest-mlogloss:0.511232\n",
      "[1030]\ttrain-mlogloss:0.415192\ttest-mlogloss:0.511125\n",
      "[1040]\ttrain-mlogloss:0.414313\ttest-mlogloss:0.510913\n",
      "[1050]\ttrain-mlogloss:0.413437\ttest-mlogloss:0.510771\n",
      "[1060]\ttrain-mlogloss:0.412603\ttest-mlogloss:0.510653\n",
      "[1070]\ttrain-mlogloss:0.411688\ttest-mlogloss:0.510552\n",
      "[1080]\ttrain-mlogloss:0.410782\ttest-mlogloss:0.510504\n",
      "[1090]\ttrain-mlogloss:0.409955\ttest-mlogloss:0.510404\n",
      "[1100]\ttrain-mlogloss:0.409099\ttest-mlogloss:0.510304\n",
      "[1110]\ttrain-mlogloss:0.408316\ttest-mlogloss:0.510222\n",
      "[1120]\ttrain-mlogloss:0.407555\ttest-mlogloss:0.510152\n",
      "[1130]\ttrain-mlogloss:0.406736\ttest-mlogloss:0.510147\n",
      "[1140]\ttrain-mlogloss:0.405997\ttest-mlogloss:0.510082\n",
      "[1150]\ttrain-mlogloss:0.405154\ttest-mlogloss:0.510024\n",
      "[1160]\ttrain-mlogloss:0.404425\ttest-mlogloss:0.509923\n",
      "[1170]\ttrain-mlogloss:0.403621\ttest-mlogloss:0.509872\n",
      "[1180]\ttrain-mlogloss:0.402837\ttest-mlogloss:0.509779\n",
      "[1190]\ttrain-mlogloss:0.4021\ttest-mlogloss:0.509702\n",
      "[1200]\ttrain-mlogloss:0.401371\ttest-mlogloss:0.509682\n",
      "[1210]\ttrain-mlogloss:0.400647\ttest-mlogloss:0.509556\n",
      "[1220]\ttrain-mlogloss:0.399904\ttest-mlogloss:0.509497\n",
      "[1230]\ttrain-mlogloss:0.399205\ttest-mlogloss:0.509458\n",
      "[1240]\ttrain-mlogloss:0.398297\ttest-mlogloss:0.509366\n",
      "[1250]\ttrain-mlogloss:0.39762\ttest-mlogloss:0.509317\n",
      "[1260]\ttrain-mlogloss:0.39692\ttest-mlogloss:0.509236\n",
      "[1270]\ttrain-mlogloss:0.396036\ttest-mlogloss:0.509188\n",
      "[1280]\ttrain-mlogloss:0.395289\ttest-mlogloss:0.509143\n",
      "[1290]\ttrain-mlogloss:0.394581\ttest-mlogloss:0.509097\n",
      "[1300]\ttrain-mlogloss:0.393934\ttest-mlogloss:0.509063\n",
      "[1310]\ttrain-mlogloss:0.393086\ttest-mlogloss:0.509036\n",
      "[1320]\ttrain-mlogloss:0.392431\ttest-mlogloss:0.508965\n",
      "[1330]\ttrain-mlogloss:0.391592\ttest-mlogloss:0.50894\n",
      "[1340]\ttrain-mlogloss:0.390908\ttest-mlogloss:0.508844\n",
      "[1350]\ttrain-mlogloss:0.390285\ttest-mlogloss:0.508773\n",
      "[1360]\ttrain-mlogloss:0.389606\ttest-mlogloss:0.508701\n",
      "[1370]\ttrain-mlogloss:0.388902\ttest-mlogloss:0.508637\n",
      "[1380]\ttrain-mlogloss:0.388427\ttest-mlogloss:0.508587\n",
      "[1390]\ttrain-mlogloss:0.387723\ttest-mlogloss:0.508473\n",
      "[1400]\ttrain-mlogloss:0.386964\ttest-mlogloss:0.508423\n",
      "[1410]\ttrain-mlogloss:0.386154\ttest-mlogloss:0.508338\n",
      "[1420]\ttrain-mlogloss:0.385491\ttest-mlogloss:0.508291\n",
      "[1430]\ttrain-mlogloss:0.38478\ttest-mlogloss:0.508232\n",
      "[1440]\ttrain-mlogloss:0.384173\ttest-mlogloss:0.508164\n",
      "[1450]\ttrain-mlogloss:0.383522\ttest-mlogloss:0.508151\n",
      "[1460]\ttrain-mlogloss:0.382845\ttest-mlogloss:0.508058\n",
      "[1470]\ttrain-mlogloss:0.38208\ttest-mlogloss:0.50798\n",
      "[1480]\ttrain-mlogloss:0.381406\ttest-mlogloss:0.50799\n",
      "[1490]\ttrain-mlogloss:0.380656\ttest-mlogloss:0.50796\n",
      "[1500]\ttrain-mlogloss:0.379952\ttest-mlogloss:0.507919\n",
      "[1510]\ttrain-mlogloss:0.379209\ttest-mlogloss:0.507848\n",
      "[1520]\ttrain-mlogloss:0.378534\ttest-mlogloss:0.507846\n",
      "[1530]\ttrain-mlogloss:0.377876\ttest-mlogloss:0.507838\n",
      "[1540]\ttrain-mlogloss:0.377245\ttest-mlogloss:0.507804\n",
      "[1550]\ttrain-mlogloss:0.376559\ttest-mlogloss:0.507794\n",
      "[1560]\ttrain-mlogloss:0.375876\ttest-mlogloss:0.507797\n",
      "[1570]\ttrain-mlogloss:0.375331\ttest-mlogloss:0.507767\n",
      "[1580]\ttrain-mlogloss:0.374699\ttest-mlogloss:0.507761\n",
      "[1590]\ttrain-mlogloss:0.374168\ttest-mlogloss:0.507764\n",
      "Stopping. Best iteration:\n",
      "[1579]\ttrain-mlogloss:0.37478\ttest-mlogloss:0.507752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def runXGB(train_X, train_y, test_X,test_y,test_final,feature_names=None, seed_val=321, num_rounds=2000):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.02\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 0\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = 20\n",
    "    #param['subsample'] = 0.7\n",
    "    #param['colsample_bytree'] = 0.7\n",
    "    param['lambda'] = 2\n",
    "    param['alpha'] = 0.02\n",
    "    param['subsample'] = 0.8\n",
    "    param['colsample_bytree'] = 0.8\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist,verbose_eval=10,early_stopping_rounds=20)\n",
    "    \n",
    "    xgtest1 = xgb.DMatrix(test_final)\n",
    "    pred_test_y = model.predict(xgtest1)\n",
    "    return pred_test_y, model\n",
    "\n",
    "preds, model = runXGB(X_train,y_train,X_test,y_test,test_X, num_rounds=2000)\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df.to_csv(\"sub54_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 1000\n",
    "epochs = 20\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "X_train,y_train,X_test,y_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train = X_train.astype('float32').todense()\n",
    "X_test = X_test.astype('float32').todense()\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(300, activation='relu', input_shape=(240,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(300, activation='relu',name='feature_layer'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dense(300, activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<39481x240 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 1627275 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39481, 240)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Xg = graphlab.SFrame(X_train.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\n"
     ]
    }
   ],
   "source": [
    "print('abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
